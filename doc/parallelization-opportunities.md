# Parallelization Opportunities in AzerothCore

## Executive Summary

This document analyzes potential parallelization opportunities in AzerothCore using the existing WorkStealingThreadPool infrastructure. Each system is evaluated on:
- **Performance Gain**: Expected speedup from parallelization
- **Thread Safety**: Complexity of making the system thread-safe
- **Implementation Difficulty**: Effort required for implementation
- **ROI Ranking**: Overall return on investment

---

## ü•á TIER 1: High ROI - Recommended Implementation

### 1. WorldSession Updates (Player Packet Processing)

**Current Implementation:** Sequential loop in `WorldSessionMgr::UpdateSessions()`
```cpp
for (SessionMap::iterator itr = _sessions.begin(); itr != _sessions.end(); ++itr) {
    pSession->Update(diff, updater);
}
```

**Analysis:**
- **Performance Gain**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
  - Each session processes player packets independently
  - High player counts (100-1000+) = massive parallelism opportunity
  - Expected speedup: 2-4x on 8-core systems with 200+ players
  - Currently takes ~15-30% of World::Update time on populated servers

- **Thread Safety**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5 - Low Complexity)
  - Sessions are mostly independent (per-player state)
  - Shared resources: Guild, Group, LFG, Auction House
  - These managers already have locks for concurrent access
  - Main concern: Player-to-player interactions (trade, duel, group invite)

- **Implementation Difficulty**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5 - Moderate)
  - Session addition/removal must stay on main thread
  - Need to handle cross-session interactions (trading, dueling)
  - Socket operations are already thread-safe
  - Database queries already async

**Data Dependencies:**
- ‚úÖ **Independent**: Player movement, combat, spells, inventory
- ‚ö†Ô∏è **Requires Locking**: Guild operations, group operations, trade
- ‚ùå **Main Thread Only**: Session creation/deletion

**Recommended Approach:**
```cpp
void WorldSessionMgr::UpdateSessions(uint32 const diff) {
    // Add sessions on main thread
    while (_addSessQueue.next(sess))
        AddSession_(sess);

    // Parallel session updates using work-stealing pool
    if (sWorld->GetSessionUpdateThreadPool() && _sessions.size() >= 50) {
        std::vector<WorldSession*> sessionBatch;
        for (auto& [id, session] : _sessions) {
            sessionBatch.push_back(session);
            if (sessionBatch.size() >= 10) {
                threadPool->Submit([sessions = std::move(sessionBatch), diff]() {
                    for (auto* sess : sessions)
                        sess->Update(diff, ...);
                });
                sessionBatch.clear();
            }
        }
    }

    threadPool->WaitForCompletion();

    // Handle disconnections on main thread
    // ...
}
```

**Estimated ROI**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Very High)
- **Effort**: 2-3 weeks for experienced developer
- **Benefit**: 2-4x speedup for session updates (15-30% of total server time)
- **Risk**: Medium (requires careful handling of cross-player interactions)

---

### 2. Grid Loading/Preloading Parallelization

**Current Implementation:** Sequential grid loading in `Map::LoadGridsInRange()`

**Analysis:**
- **Performance Gain**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)
  - Grid loading is I/O and CPU intensive (mmaps, vmaps, spawns)
  - Startup time for large maps: 30-120 seconds
  - Expected speedup: 3-6x on 8-core systems
  - Reduces player teleport lag

- **Thread Safety**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5 - Very Low Complexity)
  - Grids are independent before activation
  - No shared mutable state during loading
  - Already has `MapPreloadRequest` async support
  - Only need to parallelize within a single map's grid batch

- **Implementation Difficulty**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5 - Easy)
  - Grid loading is already designed to be async-safe
  - Minimal changes to existing code
  - Can reuse MapUpdater's thread pool

**Data Dependencies:**
- ‚úÖ **Fully Independent**: Each grid loads from disk independently
- ‚úÖ **Thread-Safe**: Grid activation happens on main thread after loading

**Recommended Approach:**
```cpp
void Map::LoadGridsInRange(Position const& center, float radius) {
    std::vector<std::pair<uint32, uint32>> gridsToLoad;

    // Collect grid coordinates
    for (uint32 x = ...; x < ...; ++x)
        for (uint32 y = ...; y < ...; ++y)
            if (!IsGridLoaded(x, y))
                gridsToLoad.push_back({x, y});

    // Parallel grid loading
    MapUpdater* updater = sMapMgr->GetMapUpdater();
    for (auto [x, y] : gridsToLoad) {
        updater->submit_task([this, x, y]() {
            LoadGridData(x, y);  // Load from disk
        });
    }

    updater->wait();

    // Activate grids on main thread
    for (auto [x, y] : gridsToLoad)
        ActivateGrid(x, y);
}
```

**Estimated ROI**: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Very High)
- **Effort**: 1 week
- **Benefit**: 3-6x faster server startup and teleports
- **Risk**: Very Low (grids are independent)

---

## ü•à TIER 2: Good ROI - Consider for Next Phase

### 3. Batch Pathfinding (Multiple Simultaneous Paths)

**Current Implementation:** Each creature calculates path sequentially

**Analysis:**
- **Performance Gain**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)
  - PathGenerator::BuildPolyPath is CPU-intensive (5-50ms per path)
  - High-density areas: 20-50 creatures pathfinding per update
  - Expected speedup: 2-3x for pathfinding operations
  - Pathfinding takes ~5-10% of update time on populated maps

- **Thread Safety**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5 - Low Complexity)
  - MMAP data is read-only (thread-safe)
  - Each path calculation is independent
  - Result is position vector (no shared state)
  - Main concern: NavMesh queries (underlying Recast library thread-safety)

- **Implementation Difficulty**: ‚≠ê‚≠ê‚≠ê (3/5 - Moderate-Hard)
  - Need to verify Recast/Detour thread-safety
  - May need per-thread NavMesh query objects
  - Path results must be applied on main thread
  - Complex integration with movement generators

**Data Dependencies:**
- ‚úÖ **Independent**: Each path calculation is isolated
- ‚ö†Ô∏è **Verify**: Recast NavMesh query thread-safety
- ‚ùå **Main Thread Only**: Applying path results to creature movement

**Recommended Approach:**
```cpp
// Collect pathfinding requests during map update
struct PathRequest {
    Creature* creature;
    Position destination;
    std::promise<std::vector<G3D::Vector3>> result;
};

void Map::UpdateNonPlayerObjectsParallel(...) {
    std::vector<PathRequest> pathRequests;

    // Batch parallel pathfinding
    for (auto& req : pathRequests) {
        updater->submit_task([req]() {
            PathGenerator gen(req.creature);
            gen.CalculatePath(req.destination);
            req.result.set_value(gen.GetPath());
        });
    }

    updater->wait();

    // Apply results on main thread
    for (auto& req : pathRequests) {
        auto path = req.result.get_future().get();
        req.creature->GetMotionMaster()->ApplyPath(path);
    }
}
```

**Estimated ROI**: ‚≠ê‚≠ê‚≠ê‚≠ê (High)
- **Effort**: 2-4 weeks (includes Recast thread-safety investigation)
- **Benefit**: 2-3x speedup for pathfinding (5-10% of total time)
- **Risk**: Medium (depends on Recast library thread-safety)

---

### 4. Async Database Query Processing (Enhanced)

**Current Implementation:** Async queries exist but callbacks execute on single thread

**Analysis:**
- **Performance Gain**: ‚≠ê‚≠ê‚≠ê (3/5)
  - Query callbacks can be CPU-intensive (processing results)
  - Currently all callbacks execute sequentially in `ProcessQueryCallbacks()`
  - Expected speedup: 1.5-2x for query processing
  - Low impact unless many slow queries

- **Thread Safety**: ‚≠ê‚≠ê‚≠ê (3/5 - Moderate Complexity)
  - Callbacks may access game world state
  - Database connection pool already thread-safe
  - Need to ensure callbacks don't modify shared state unsafely

- **Implementation Difficulty**: ‚≠ê‚≠ê‚≠ê (3/5 - Moderate)
  - Existing QueryCallback infrastructure
  - Need to categorize callbacks by safety
  - Some callbacks must execute on main thread

**Data Dependencies:**
- ‚úÖ **Independent**: Read-only query result processing
- ‚ö†Ô∏è **Requires Locking**: Callbacks that modify managers (ObjectMgr, etc.)
- ‚ùå **Main Thread Only**: Callbacks that spawn objects or modify world

**Recommended Approach:**
```cpp
// Add flag to QueryCallback for thread safety
enum CallbackExecutionContext {
    CONTEXT_MAIN_THREAD,        // Must run on main thread
    CONTEXT_WORKER_THREAD_SAFE  // Can run in parallel
};

class QueryCallback {
    CallbackExecutionContext _context;

    QueryCallback& WithContext(CallbackExecutionContext ctx) {
        _context = ctx;
        return *this;
    }
};

void World::ProcessQueryCallbacks() {
    auto callbacks = _queryProcessor.GetReadyCallbacks();

    // Parallel processing of thread-safe callbacks
    for (auto& cb : callbacks) {
        if (cb->IsThreadSafe()) {
            threadPool->Submit([cb]() { cb->Execute(); });
        } else {
            mainThreadCallbacks.push_back(cb);
        }
    }

    threadPool->wait();

    // Execute main-thread-only callbacks
    for (auto& cb : mainThreadCallbacks)
        cb->Execute();
}
```

**Estimated ROI**: ‚≠ê‚≠ê‚≠ê (Medium)
- **Effort**: 2-3 weeks
- **Benefit**: 1.5-2x speedup for query callback processing
- **Risk**: Medium (requires careful callback categorization)

---

## ü•â TIER 3: Lower ROI - Future Consideration

### 5. Visibility Update Calculations

**Analysis:**
- **Performance Gain**: ‚≠ê‚≠ê‚≠ê (3/5)
  - UpdateVisibilityOf checks are expensive
  - High player density = many visibility checks
  - Expected speedup: 1.5-2x
  - Takes ~5-8% of update time

- **Thread Safety**: ‚≠ê‚≠ê (2/5 - High Complexity)
  - Visibility updates modify player packet data
  - UpdateData objects are not thread-safe
  - Grid queries may not be thread-safe
  - Complex interaction with phases, stealth, visibility modifiers

- **Implementation Difficulty**: ‚≠ê‚≠ê (2/5 - Very Hard)
  - Deeply integrated with packet system
  - Many special cases (stealth, phase, invisibility)
  - High risk of race conditions

**Estimated ROI**: ‚≠ê‚≠ê (Low)
- **Effort**: 4-6 weeks
- **Benefit**: 1.5-2x speedup for visibility (5-8% of total time)
- **Risk**: High (complex packet interactions)

**Recommendation**: ‚ö†Ô∏è Wait for higher ROI opportunities first

---

### 6. Loot Generation Parallelization

**Analysis:**
- **Performance Gain**: ‚≠ê‚≠ê (2/5)
  - Loot generation is relatively fast (0.1-1ms per creature)
  - Only matters when many creatures die simultaneously (rare)
  - Expected speedup: 2-3x for loot generation
  - Takes <1% of update time (not a bottleneck)

- **Thread Safety**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5 - Low Complexity)
  - LootTemplate is read-only
  - Random number generation can be per-thread
  - Loot items are independent

- **Implementation Difficulty**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5 - Easy-Moderate)
  - Straightforward batching
  - Main complexity: ensuring deterministic RNG if needed

**Estimated ROI**: ‚≠ê‚≠ê (Low)
- **Effort**: 1-2 weeks
- **Benefit**: Minimal (loot generation is not a bottleneck)
- **Risk**: Low

**Recommendation**: ‚ö†Ô∏è Low priority, loot generation is already fast

---

### 7. Spell/Aura Batch Processing

**Analysis:**
- **Performance Gain**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)
  - Aura updates are CPU-intensive
  - Many independent aura ticks
  - Expected speedup: 2-3x for aura processing
  - Takes ~10-15% of Unit::Update time

- **Thread Safety**: ‚≠ê (1/5 - Very High Complexity)
  - Auras can modify stats, health, mana
  - Spell interactions are complex (interrupts, dispels)
  - Many auras trigger other spells
  - Unit state is heavily shared

- **Implementation Difficulty**: ‚≠ê (1/5 - Extremely Hard)
  - Spell system is tightly coupled
  - Massive risk of race conditions
  - Would require major architectural changes
  - High risk of introducing subtle bugs

**Estimated ROI**: ‚≠ê (Very Low - Do Not Implement)
- **Effort**: 8-12 weeks (very high risk)
- **Benefit**: 2-3x speedup for spell processing
- **Risk**: EXTREME (high chance of introducing critical bugs)

**Recommendation**: ‚ùå **DO NOT IMPLEMENT**
- Spell/aura system is too complex and interdependent
- Risk far outweighs benefit
- Would require fundamental architectural redesign

---

## Summary Ranking by ROI

| Rank | System | Effort | Benefit | Risk | ROI Score | Recommendation |
|------|--------|--------|---------|------|-----------|----------------|
| 1 | **Grid Loading** | 1 week | 3-6x speedup | Very Low | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ **Implement Next** |
| 2 | **Session Updates** | 2-3 weeks | 2-4x speedup | Medium | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ **Implement After Grid** |
| 3 | **Pathfinding** | 2-4 weeks | 2-3x speedup | Medium | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ Consider for Phase 2 |
| 4 | **DB Callbacks** | 2-3 weeks | 1.5-2x speedup | Medium | ‚≠ê‚≠ê‚≠ê | ‚ö†Ô∏è Lower priority |
| 5 | **Visibility** | 4-6 weeks | 1.5-2x speedup | High | ‚≠ê‚≠ê | ‚ö†Ô∏è Wait for better options |
| 6 | **Loot Generation** | 1-2 weeks | Minimal | Low | ‚≠ê‚≠ê | ‚ö†Ô∏è Not a bottleneck |
| 7 | **Spell/Aura** | 8-12 weeks | 2-3x speedup | EXTREME | ‚≠ê | ‚ùå **Do Not Implement** |

---

## Recommended Implementation Order

### Phase 1: Low-Hanging Fruit (Quick Wins)
1. **Grid Loading Parallelization** (1 week)
   - Minimal risk, high impact on startup/teleports
   - Can be implemented independently

### Phase 2: High-Impact Parallelism
2. **WorldSession Updates** (2-3 weeks)
   - Highest overall performance impact
   - Requires careful cross-session interaction handling

### Phase 3: Specialized Optimization
3. **Batch Pathfinding** (2-4 weeks)
   - Depends on Recast library thread-safety verification
   - Significant benefit for high-density areas

### Phase 4: Advanced (Optional)
4. **Database Callback Processing** (2-3 weeks)
   - Lower impact, but useful for DB-heavy workloads
   - Requires careful callback categorization

---

## Implementation Guidelines

### Before Starting Any Parallelization:
1. ‚úÖ Profile to confirm bottleneck
2. ‚úÖ Write comprehensive unit tests
3. ‚úÖ Document thread-safety assumptions
4. ‚úÖ Add ThreadSanitizer runs to CI

### During Implementation:
1. ‚úÖ Use WorkStealingThreadPool for all parallelization
2. ‚úÖ Follow batch-based approach (not per-object)
3. ‚úÖ Add adaptive thresholds (like Map parallel updates)
4. ‚úÖ Include exception handling in all worker tasks
5. ‚úÖ Add metrics for parallel vs sequential performance

### After Implementation:
1. ‚úÖ Run ThreadSanitizer for data race detection
2. ‚úÖ Benchmark with realistic workloads
3. ‚úÖ Test with stress scenarios (1000+ players)
4. ‚úÖ Document configuration options
5. ‚úÖ Provide fallback to sequential if issues detected

---

## Conclusion

The **Grid Loading** and **Session Updates** parallelization opportunities offer the best ROI:
- High performance gains (2-6x speedups)
- Reasonable implementation complexity
- Manageable thread-safety concerns
- Clear architectural boundaries

The **Spell/Aura system** should NOT be parallelized due to extreme complexity and risk.

Total potential server performance improvement: **30-50% reduction in update time** if Tier 1 + Tier 2 opportunities are implemented.
